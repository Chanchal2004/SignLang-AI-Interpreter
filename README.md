# ğŸ–ï¸ Sign Language Recognition & Text-to-Speech System

A real-time **American Sign Language (ASL)** recognition system that converts hand gestures into **text and speech** using **Computer Vision** and **Deep Learning**. Built with **Python, OpenCV, TensorFlow**, and a custom-trained **CNN model**, this project empowers accessibility by enabling **hands-free communication** through sign language.

---

## ğŸ“¸ Demo Video  
ğŸ”— https://drive.google.com/file/d/16yT3klPjl3PsZSrgbyzHKy-9Tp2QJMB_/view?usp=sharing

---

## ğŸš€ Features

### âœ… Core Functionalities
- **Hand Gesture Recognition:** Real-time detection using `cvzone`'s HandDetector (21-point landmarks).  
- **Alphabet Prediction (Aâ€“Z):** CNN trained on 26 classes using skeletonized hand images (accuracy **>95%**).  
- **Text-to-Speech Conversion:** Converts constructed sentences into speech using `pyttsx3`.  

### âœ… Word & Sentence Suggestions
- **Next Word Prediction:** Trigram Language Model trained using the Brown Corpus (`NLTK`).  
- **Auto Spell Correction:** Implemented using **SymSpell** based on dictionary frequency & edit distance.

### âœ… Gesture Controls
- âœ‹ **Open Hand â†’ Insert Space**  
- ğŸ‘ **Thumb Out â†’ Backspace**  
- âœ… Completely **hands-free operation** (no keyboard needed)

---

## ğŸ§  Model Architecture

### ğŸ”¹ Input
- **55Ã—55 grayscale skeletonized gesture images**

### ğŸ”¹ Layers
- **3Ã— Conv2D + BatchNorm + MaxPooling + Dropout**  
- Dense Layers: **512 â†’ 256** neurons (+ Dropout)  
- Output: **Softmax (26 classes Aâ€“Z)**

### ğŸ”¹ Training Techniques
- Data Augmentation (Rotation, Zoom, Shear, Flip)  
- Early Stopping  
- ReduceLROnPlateau  
- ModelCheckpoint (best validation accuracy)  

---

## ğŸ“¸ GUI Overview (Tkinter)
- Live camera feed panel  
- Skeleton drawing panel  
- Real-time prediction + confidence score  
- Sentence builder with:
  - Word suggestions  
  - Next-word prediction  
- Control buttons: **Speak**, **Auto-Correct**, **Backspace**, **Clear**

---

## ğŸ“ File Structure
```
â”œâ”€â”€ alphabetPred.py         # Skeleton-to-letter prediction
â”œâ”€â”€ final1pred.py           # Full ASL-to-speech GUI system
â”œâ”€â”€ handAcquisition.py      # Data collection tool
â”œâ”€â”€ trainmodel.py           # CNN training script
â”œâ”€â”€ AtoZ_3.1/               # Dataset (26 folders Aâ€“Z)
â”œâ”€â”€ model-bw.weights.h5     # Trained model weights
â”œâ”€â”€ best_model.h5           # Best accuracy model
â”œâ”€â”€ model-bw.json           # CNN architecture
```

---

## ğŸ†• Unique Aspects
- **Skeleton-Based Images:** More noise-resistant and adaptable than raw RGB.  
- **Gesture-Based Control:** Space & backspace using hand gestures only.  
- **Context-Aware Suggestions:** Powered by NLP models.  

---

## ğŸ§ª Future Enhancements
- Dynamic gesture recognition (motion-based signs)  
- Number and phrase-level ASL support  
- Web / mobile deployment (Flask, Kivy)  
- Multi-hand detection & multi-user support  

---

## ğŸ› ï¸ Technologies Used
**Python, OpenCV, TensorFlow/Keras, cvzone, NLTK, SymSpell, Tkinter, Pyttsx3**
